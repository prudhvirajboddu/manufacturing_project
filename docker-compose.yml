version: "3.8"

services:
  # ðŸŸ¢ MongoDB for storing sensor data
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    restart: always
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - manufacturing_network

  # ðŸŸ¡ Zookeeper (Required for Kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - manufacturing_network

  # ðŸ”´ Kafka Broker (Message Queue)
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    restart: always
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper
    networks:
      - manufacturing_network

  # ðŸ”µ Spark Standalone Master
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      - SPARK_MODE=master
    networks:
      - manufacturing_network

  # ðŸ”µ Spark Worker
  spark-worker:
    image: bitnami/spark:3.5.0
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - manufacturing_network

  # ðŸŸ  Python Sensor Data Generator
  sensor-data-generator:
    build: ./sensor_simulator
    container_name: sensor-generator
    depends_on:
      - kafka
    networks:
      - manufacturing_network

  # ðŸŸ£ Spark Streaming Consumer (Kafka â†’ MongoDB)
  spark-streaming:
    build: ./spark_streaming
    container_name: spark-streaming
    depends_on:
      - kafka
      - mongodb
    environment:
      - PYSPARK_SUBMIT_ARGS=--jars /opt/bitnami/spark/jars/spark-sql-kafka-0-10_2.12-3.5.0.jar,/opt/bitnami/spark/jars/kafka-clients-3.5.0.jar pyspark-shell
    networks:
      - manufacturing_network

volumes:
  mongodb_data:

networks:
  manufacturing_network:
    driver: bridge
